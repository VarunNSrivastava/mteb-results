{
    "test": {
        "cos_sim": {
            "accuracy": 0.8607617571675508,
            "accuracy_threshold": 0.7252891063690186,
            "ap": 0.7385398650568216,
            "f1": 0.6850702798531088,
            "f1_threshold": 0.6927633881568909,
            "precision": 0.6586316045775505,
            "recall": 0.7137203166226913
        },
        "dot": {
            "accuracy": 0.8607617571675508,
            "accuracy_threshold": 0.7252891063690186,
            "ap": 0.738539834623843,
            "f1": 0.6850702798531088,
            "f1_threshold": 0.6927634477615356,
            "precision": 0.6586316045775505,
            "recall": 0.7137203166226913
        },
        "euclidean": {
            "accuracy": 0.8607617571675508,
            "accuracy_threshold": 0.741229772567749,
            "ap": 0.7385398625060356,
            "f1": 0.6850702798531088,
            "f1_threshold": 0.7838833928108215,
            "precision": 0.6586316045775505,
            "recall": 0.7137203166226913
        },
        "evaluation_time": 10.46,
        "manhattan": {
            "accuracy": 0.8598676759849795,
            "accuracy_threshold": 16.310482025146484,
            "ap": 0.7386874126878737,
            "f1": 0.6855096559662361,
            "f1_threshold": 16.945289611816406,
            "precision": 0.6651774633904195,
            "recall": 0.7071240105540897
        },
        "max": {
            "accuracy": 0.8607617571675508,
            "ap": 0.7386874126878737,
            "f1": 0.6855096559662361
        }
    },
    "mteb_version": "0.0.2",
    "mteb_dataset_name": "TwitterSemEval2015",
    "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1"
}